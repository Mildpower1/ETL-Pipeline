{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5091587a",
   "metadata": {},
   "source": [
    "### ETL (Extract, Transform, Load)\n",
    "\n",
    "    - ETL and ELT are two common data integration methodologies. \n",
    "      ETL involves extracting raw data from various sources, transforming it to meet specific requirements,\n",
    "      and then loading it into a target database.\n",   
    "### ELT  (Extract, Load, Transform) \n",
    "\n",
    "    - In contrast, ELT directly loads raw data into a data warehouse and performs data cleansing, enrichment, Tansformation\n",
    "      within the warehouse itself. \n",
    "      This approach allows for the indefinite storage of raw data, enabling multiple transformations and analyses over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e27b33",
   "metadata": {},
   "source": [
    "### Why ETL Pipelines with Python?\n",
    "\n",
    "    - Python is a popular choice for building ETL pipelines due to its:\n",
    "\n",
    "        - Simplicity: Python has a clear and readable syntax, making it easy to develop and maintain pipelines.\n",
    "\n",
    "        - Diversity: There are numerous libraries such as Pandas, NumPy, SQLAlchemy, and PySpark that are specifically \n",
    "          designed for data manipulation and analysis.\n",
    "\n",
    "        - Community: Python has a large and active community that is constantly developing new tools and resources.        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab5739",
   "metadata": {},
   "source": [
    "### Steps to create an ETL pipeline:\n",
    "\n",
    "    - Define data sources:\n",
    "\n",
    "            - Identify the sources of your data (e.g. databases, CSV files, APIs).\n",
    "            - Connect to these sources (e.g. using SQLAlchemy for databases).\n",
    "\n",
    "    - Extract data:\n",
    "\n",
    "            - Read the data from the sources (e.g. using Pandas for CSV files).\n",
    "            - Filter the data as needed.\n",
    "\n",
    "    - Transform data:\n",
    "\n",
    "            - Clean the data (e.g. removing duplicates, filling missing values).\n",
    "            - Convert data types.\n",
    "            - Aggregate data.\n",
    "            - Perform calculations.\n",
    "            \n",
    "    - Load data:\n",
    "\n",
    "            - Write the transformed data to the target system (e.g. another database, a data warehouse)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93afc8b9",
   "metadata": {},
   "source": [
    "### A very simple Pipeline\n",
    "\n",
    " import pandas as pd\n",
    " from sqlalchemy import create_engine\n",
    "\n",
    " - Extract data from a CSV file\n",
    " df = pd.read_csv('data.csv')\n",
    "\n",
    " - Transform data\n",
    " df['Date'] = pd.to_datetime(df['Date'])\n",
    " df['amount'] = df['amount'].astype(float)\n",
    "\n",
    " - Connecting to a PostgreSQL database\n",
    " engine = create_engine('postgresql://user:password@host:port/database')\n",
    "\n",
    " - Load data into a table\n",
    " df.to_sql('my_table', engine, if_exists='replace', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
