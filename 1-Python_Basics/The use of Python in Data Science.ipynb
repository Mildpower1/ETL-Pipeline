{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79604156",
   "metadata": {},
   "source": [
    "## The following Python basics should be known beforehand:\n",
    "\n",
    "    - Data Structure (List, Dictionary, Tuple and Sets)\n",
    "    - Conditions statements (if...else)\n",
    "    - Looping techniques (for loop and while loop)\n",
    "    - Functions\n",
    "    - Object-oriented Programming (OOP Python)\n",
    "    - Working with files (Open, read, write, append and close)\n",
    "    - Version control with Git tracking\n",
    "    - Local integrated development environments IDEs (Jupyter Notebook, PyCharm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc3933",
   "metadata": {},
   "source": [
    "## Libraries:\n",
    "\n",
    "Some of the most popular libraries of Python are:\n",
    "\n",
    "    - Numpy for scientific computing\n",
    "    - Pandas for data manipulation and analysis.\n",
    "    - Matplotlib for visualizing data.\n",
    "    - Scikit-learn to train machine learning models.\n",
    "    \n",
    "And many more!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb938b",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "Pandas introduces the DataFrame class. A DataFrame is in the form of a matrix whose rows and columns each have an index.\n",
    "The main features of pandas are:\n",
    "\n",
    "    - data recovery from files (CSV, Excel tables, etc.)\n",
    "    - handling this data (deletion / addition, modification, statistical visualization, etc.)\n",
    "    \n",
    "#### Data Loading\n",
    "\n",
    "    - Read CSV file: df = pd.read_csv('filename.csv')\n",
    "    - Read CSV with specific delimiter: df = pd.read_csv('filename.csv', delimiter=';')\n",
    "    - Read Excel file: df = pd.read_excel('filename.xlsx')\n",
    "    - Read from SQL Database: df = pd.read_sql(query, connection)\n",
    "    - Chunking large files: pd.read_csv('large_file.csv', chunksize=1000)\n",
    "    - Iterating through data chunks: \n",
    "      for chunk in pd.read_csv('file.csv', chunksize=500); process(chunk)\n",
    "    \n",
    "#### Data Inspection\n",
    "\n",
    "    - Display top rows: df.head()\n",
    "    - Display bottom rows: df.tail()\n",
    "    - Display data type: df.dtypes\n",
    "    - Summyry statistics: df.describe()\n",
    "    - Display index, columns, and data: df.info()\n",
    "    \n",
    "#### Data Cleaning\n",
    "\n",
    "    - Check for missing values: df.isnull().sum()\n",
    "    - Fill missing values: df.fillna(value)\n",
    "    - Drop missing values: df.dropna()\n",
    "    - Rename columns: df.rename(columns={'old_name': 'new_name'})\n",
    "    - Drop columns: df.drop(columns=['collumn_name'])\n",
    "    \n",
    "#### Data Transformation    \n",
    "\n",
    "    - Apply function: df['column'].apply(lambda x: function(x))\n",
    "    - Group by and aggregate: df.groupby('column').agg({'column': 'sum'})\n",
    "    - Group by multiple columns: df.groupby(['col1', 'col2']).mean()\n",
    "    - Aggregate using multiple functions: df.groupby('col').agg(['mean', 'sum'])\n",
    "    - Transform function: df.groupby('col').transform(lambda x: x - x.mean())\n",
    "    - Pivot tables: df.pivot_table(index='column1', values='column2', aggfunc='mean')\n",
    "    - Merge dataFrames: pd.merge(df1, df2, on='column')\n",
    "    - SQL-like joins: pd.merge(df1, df2, how='left', on='col')\n",
    "    - Concatenate dataFrames: pd.concat([df1, df2])\n",
    "    - Concatenating along a different axis: pd.concat([df1, df2], axis=1)\n",
    "    - Lambda function: df.apply(lalmbda x: x+1)\n",
    "    - Pivot longer/wider format: df.melt(id_vars=['col1'])\n",
    "    - Stack/Unstack: df.stack(), df.unstack()\n",
    "    - Cross tabulations: pd.crosstab(df['col1'], df['col2'])\n",
    " \n",
    "    \n",
    "#### Data Visualization Integration\n",
    "\n",
    "    - Histogram: df['column'].hist()\n",
    "    - Boxplot: df.boxplot(column=['column1', 'column2'])\n",
    "    - Scatter plot: df.plot.scatter(x='col1', y='col2')\n",
    "    - Line plot: df.plot.line()\n",
    "    - Bar chart: df['column'].value_counts().plot.bar()\n",
    "    - Custom plotting: \n",
    "      import matplotlib.pylot as plt; df.plot(); plt.show()\n",
    "     \n",
    "    - Customize plot style: plt.style.use('ggplot')\n",
    "    - Histogram using bins specification: df['column'].hist(bins=20)\n",
    "    - Boxplot grouped by category: df.boxplot(column='num_column', by='cat_column')\n",
    "    \n",
    "#### Statistical Analysis\n",
    "\n",
    "    - Correlation matrix: df.corr()\n",
    "    - Covariance matrix: df.cov()\n",
    "    - Value counts: df['column'].value_counts()\n",
    "    - Unique values in column: df['column'].unique()\n",
    "    - Number of unique values: df['column'].nunique()\n",
    "    \n",
    "#### Indexing and Selection\n",
    "\n",
    "    - Select column: df['column']\n",
    "    - Select multiple columns: df[['col1', 'col2']]\n",
    "    - Select rows by position: df.iloc[0:5]\n",
    "    - Select rows by lable: df.loc[0:5]\n",
    "    - Conditional selection: df[df['column']> value]\n",
    "    - Query function: df.query('column'> value')\n",
    "    - Filtering using isin: df[df['column'].isin([value1, value2])]\n",
    "    - Creating multiIndex: df.set_index(['col1', 'col2'])\n",
    "    - Slicing on multiIndex: df.loc[(slice('index1_start', 'index1_end'), slice('index2_start', 'index2_end))]\n",
    "    \n",
    "#### Data Formatting and Conversion\n",
    "\n",
    "    - Convert data types: df['column'].astype('type')\n",
    "    - String operations: df['column'].str.lower()\n",
    "    - Datetime conversion: pd.to_datetime(df['column'])\n",
    "    - Setting index: df.set_index('column')\n",
    "    \n",
    "#### Handling Time Series Data\n",
    "\n",
    "    - Set datetime index: df.set_index(pd.to_datetime(df['date']))\n",
    "    - Resampling data: df.resample('M').mean()\n",
    "    - Rolling window operations: df.rolling(window=5).mean()\n",
    "    \n",
    "#### File Export\n",
    "\n",
    "    - Write to csv: df.to_csv('filename.csv')\n",
    "    - Write to excel: df.to_excel('filename.csv')\n",
    "    - Write to SQL Database: df.to_sql('table_name', connection)\n",
    "    \n",
    "#### Data Exploration Techniques\n",
    "\n",
    "    - Profile report using pandas-profiling: \n",
    "      from pandas-profiling import profileReport; profileReport(df)\n",
    "    \n",
    "    - Pairplot using seaborn: \n",
    "      import seaborn as sns; sns.pairplot(df)\n",
    "      \n",
    "    - Heatmap for correlation using seaborn: \n",
    "      sns.heatmap(df.corr(), annot=True)\n",
    "      \n",
    "#### Data Merging Techniques\n",
    "\n",
    "    - Outer join: pd.merge(df1, df2, on='column', how='outer')\n",
    "    - Inner join: pd.merge(df1, df2, on='column', how='inner')\n",
    "    - Left join: pd.merge(df1, df2, on='column', how='left')\n",
    "    - Right join: pd.merge(df1, df2, on='column', how='right')\n",
    "    \n",
    "#### Dealing using Duplicates\n",
    "\n",
    "    - Finding Duplicates: df.duplicated()\n",
    "    - Removing Duplicates: df.drop_duplicates()\n",
    "    \n",
    "#### Custom Operations using Apply\n",
    "\n",
    "    - Custom apply functions: df.apply(lambda rom:custom_func(row['col1'], row['col2'), axis=1]\n",
    "    \n",
    "#### Performance Tuning\n",
    "\n",
    "    - Using swifter for faster apply: \n",
    "      import swifer; df['column'].swifter.apply(lambda x: func(x))\n",
    "      \n",
    "    - Parallel processing using dask: \n",
    "      import dask.dataframe as dd; ddf= dd.from_pandas(df, npartitions=10)\n",
    "      \n",
    "#### Data Normalization and Standardization\n",
    "\n",
    "    - Min-Max Normalization: (df['column'] - df['column'].min()) /(df['column'].max() - df['column'].min())\n",
    "    - Z-score standardization: (df['column'] - df['column'].mean()) /(df['column'].std()\n",
    "    \n",
    "#### Working with JSON and XML\n",
    "\n",
    "    - Reading JSON: df = pd.read_json('filename.json')\n",
    "    - Reading XML: df = pd.read_xml('filename.xml')\n",
    "    - Writing to JSON: df.to_json('filename.json')\n",
    "    \n",
    "#### Dealing with Missing Data\n",
    "\n",
    "    - Interpolate missing values: df['column'].interpolate()\n",
    "    - Forward fill missing values: df['column'].ffill()\n",
    "    - Backward fill missing values: df['column'].bfill()\n",
    "    \n",
    "#### Working with External Data Source\n",
    "\n",
    "    - Reading data from HTML: dfs = pd.read_html('http://example.com')\n",
    "    - Connecting to a SQL database: \n",
    "      from sqlalchemy import create_engine\n",
    "      engine = create_engine('sqlite:///db.sqlite')\n",
    "      df = pd.read_sql('SELECT * FROM tabel_name', engine)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
